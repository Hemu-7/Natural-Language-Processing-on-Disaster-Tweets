{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9641304,"sourceType":"datasetVersion","datasetId":5887487}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T13:18:15.713097Z","iopub.execute_input":"2024-10-16T13:18:15.71404Z","iopub.status.idle":"2024-10-16T13:18:16.099363Z","shell.execute_reply.started":"2024-10-16T13:18:15.713995Z","shell.execute_reply":"2024-10-16T13:18:16.097299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom catboost import CatBoostClassifier as CB\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:23.654847Z","iopub.execute_input":"2024-10-16T13:18:23.655802Z","iopub.status.idle":"2024-10-16T13:18:24.836514Z","shell.execute_reply.started":"2024-10-16T13:18:23.655759Z","shell.execute_reply":"2024-10-16T13:18:24.835707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nlp-dataset/train.csv')\ntest_df = pd.read_csv('/kaggle/input/nlp-dataset/test.csv')\n\ntarget_train = train_df['target']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:28.492465Z","iopub.execute_input":"2024-10-16T13:18:28.49353Z","iopub.status.idle":"2024-10-16T13:18:28.597505Z","shell.execute_reply.started":"2024-10-16T13:18:28.493488Z","shell.execute_reply":"2024-10-16T13:18:28.596416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Target'] = train_df['target'].copy()\ntrain_df.pop('target')\n\ntrain_df.fillna('NaN', inplace=True)\ntest_df.fillna('NaN', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:31.985669Z","iopub.execute_input":"2024-10-16T13:18:31.986091Z","iopub.status.idle":"2024-10-16T13:18:32.001568Z","shell.execute_reply.started":"2024-10-16T13:18:31.986051Z","shell.execute_reply":"2024-10-16T13:18:32.000452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    # Remove links\n    text = re.sub(r'http[s]?://\\S+', '', text)  # Removes URLs\n    # Remove punctuation and numbers\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Removes punctuation and numbers\n    # Remove extra whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text.lower()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:36.306973Z","iopub.execute_input":"2024-10-16T13:18:36.307335Z","iopub.status.idle":"2024-10-16T13:18:36.312728Z","shell.execute_reply.started":"2024-10-16T13:18:36.307301Z","shell.execute_reply":"2024-10-16T13:18:36.311715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:39.241952Z","iopub.execute_input":"2024-10-16T13:18:39.242817Z","iopub.status.idle":"2024-10-16T13:18:40.563642Z","shell.execute_reply.started":"2024-10-16T13:18:39.242774Z","shell.execute_reply":"2024-10-16T13:18:40.562644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nlem = WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    tokens = word_tokenize(text)\n    tokens = [i for i in tokens if i not in set(stopwords.words('english'))]\n    lemmatized_text = ' '.join([lem.lemmatize(token) for token in tokens])\n\n    return lemmatized_text","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:45.387487Z","iopub.execute_input":"2024-10-16T13:18:45.388438Z","iopub.status.idle":"2024-10-16T13:18:45.873165Z","shell.execute_reply.started":"2024-10-16T13:18:45.388395Z","shell.execute_reply":"2024-10-16T13:18:45.872279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_change = ['text'] #'keyword', 'location']\nfor col in to_change:\n    train_df[col] = train_df[col].apply(clean_text)\n    test_df[col] = test_df[col].apply(clean_text)\n    \n    train_df[col] = train_df[col].apply(lemmatize_text)\n    test_df[col] = test_df[col].apply(lemmatize_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:18:49.389914Z","iopub.execute_input":"2024-10-16T13:18:49.39032Z","iopub.status.idle":"2024-10-16T13:19:14.051188Z","shell.execute_reply.started":"2024-10-16T13:18:49.390282Z","shell.execute_reply":"2024-10-16T13:19:14.050199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:19:17.742304Z","iopub.execute_input":"2024-10-16T13:19:17.742674Z","iopub.status.idle":"2024-10-16T13:19:17.757756Z","shell.execute_reply.started":"2024-10-16T13:19:17.742638Z","shell.execute_reply":"2024-10-16T13:19:17.756651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:19:23.090201Z","iopub.execute_input":"2024-10-16T13:19:23.091078Z","iopub.status.idle":"2024-10-16T13:19:23.101156Z","shell.execute_reply.started":"2024-10-16T13:19:23.091036Z","shell.execute_reply":"2024-10-16T13:19:23.100273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TF-IDF Vectorization**","metadata":{}},{"cell_type":"code","source":"vect_text = TfidfVectorizer(max_features=5000, stop_words='english')\nvect_keyword = TfidfVectorizer(max_features=500, stop_words='english')\nvect_location = TfidfVectorizer(max_features=500, stop_words='english')\n\ndef tfidf(data, vect, train=1):\n    tfidf = vect.fit_transform(data) if train else vect.transform(data)\n    \n    features = vect.get_feature_names_out()\n    score = tfidf.toarray()\n\n    return pd.DataFrame({features[i] : score[:, i] for i in range(len(features))})\n\ndef create_features(df, train=1):\n    text_tfidf = tfidf(df['text'], vect_text, train)\n    #keyword_tfidf = tfidf(df['keyword'], vect_keyword, train)\n    #location_tfidf = tfidf(df['location'], vect_location, train)\n    df = pd.concat((text_tfidf,df), axis=1)\n    \n    df.drop(['text', 'id', 'keyword','location'], axis=1, inplace=True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:19:26.25501Z","iopub.execute_input":"2024-10-16T13:19:26.255406Z","iopub.status.idle":"2024-10-16T13:19:26.264175Z","shell.execute_reply.started":"2024-10-16T13:19:26.255368Z","shell.execute_reply":"2024-10-16T13:19:26.263267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nids = test_df['id'].copy()\n\ntrain_df = create_features(train_df, train=1)\ntest_df = create_features(test_df, train=0)\n\nuinque_index = lambda cols: [(f\"{col}_{i}\" if list(cols).count(col) > 1 else col) for i, col in enumerate(cols)]\n\ntrain_df.columns = uinque_index(train_df.columns)\ntest_df.columns = uinque_index(test_df.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:19:32.347284Z","iopub.execute_input":"2024-10-16T13:19:32.34767Z","iopub.status.idle":"2024-10-16T13:19:40.314738Z","shell.execute_reply.started":"2024-10-16T13:19:32.347633Z","shell.execute_reply":"2024-10-16T13:19:40.313718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns.values.tolist().index('Target')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:19:50.125952Z","iopub.execute_input":"2024-10-16T13:19:50.126349Z","iopub.status.idle":"2024-10-16T13:19:50.133155Z","shell.execute_reply.started":"2024-10-16T13:19:50.126312Z","shell.execute_reply":"2024-10-16T13:19:50.132165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:20:01.830641Z","iopub.execute_input":"2024-10-16T13:20:01.831037Z","iopub.status.idle":"2024-10-16T13:20:01.83894Z","shell.execute_reply.started":"2024-10-16T13:20:01.830998Z","shell.execute_reply":"2024-10-16T13:20:01.838026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Target'].describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:20:34.214027Z","iopub.execute_input":"2024-10-16T13:20:34.214836Z","iopub.status.idle":"2024-10-16T13:20:34.228288Z","shell.execute_reply.started":"2024-10-16T13:20:34.214795Z","shell.execute_reply":"2024-10-16T13:20:34.227255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtest, xval, ytest, yval = \\\ntrain_test_split(train_df, target_train, test_size=0.2, shuffle=True, stratify=train_df['Target'])\n\nfor df in [xtest, xval, train_df]:\n    df.pop('Target')\n    \ndef is_dropping_good(xtest, xval, ytest, yval):\n    clf = CB(iterations=100, task_type='CPU', verbose=False)\n\n    clf.fit(xtest, ytest)\n\n    print(f\"f1 with all features: {f1_score(yval, clf.predict(xval))}\")\n    print(pd.DataFrame(clf.feature_importances_).describe())\n    sns.scatterplot(pd.DataFrame(clf.feature_importances_))\n    plt.show()\n    \n    print('-'*100)\n\n    print(\"shapes before\", xval.shape, xtest.shape)\n    \n    fimp = clf.feature_importances_.argsort()\n    xval.drop([xval.columns[i] for i in fimp[:len(fimp) // 2]], axis=1, inplace=True)\n    xtest.drop([xtest.columns[i] for i in fimp[:len(fimp) // 2]], axis=1, inplace=True)\n    \n    print(\"shapes after\", xval.shape, xtest.shape)\n\n    print('-'*100)\n\n    clf = CB(iterations=100, task_type='CPU', verbose=False)\n\n    clf.fit(xtest, ytest)\n\n    print(f\"f1 after dropping features: {f1_score(yval, clf.predict(xval))}\")\n    \n    return fimp","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:21:23.650625Z","iopub.execute_input":"2024-10-16T13:21:23.651014Z","iopub.status.idle":"2024-10-16T13:21:23.842686Z","shell.execute_reply.started":"2024-10-16T13:21:23.650976Z","shell.execute_reply":"2024-10-16T13:21:23.841679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clf = MultinomialNB()\nclf = CB(iterations=1000, task_type='CPU', verbose=False)\nclf.fit(train_df, target_train)\n\nf1_score(target_train, clf.predict(train_df))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:21:53.764362Z","iopub.execute_input":"2024-10-16T13:21:53.765146Z","iopub.status.idle":"2024-10-16T13:22:24.007191Z","shell.execute_reply.started":"2024-10-16T13:21:53.765107Z","shell.execute_reply":"2024-10-16T13:22:24.006266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id':ids,\n    'target':clf.predict(test_df)\n})\n\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:25:26.785638Z","iopub.execute_input":"2024-10-16T13:25:26.786277Z","iopub.status.idle":"2024-10-16T13:25:26.933003Z","shell.execute_reply.started":"2024-10-16T13:25:26.786238Z","shell.execute_reply":"2024-10-16T13:25:26.93207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:25:38.854413Z","iopub.execute_input":"2024-10-16T13:25:38.854813Z","iopub.status.idle":"2024-10-16T13:25:38.872386Z","shell.execute_reply.started":"2024-10-16T13:25:38.854774Z","shell.execute_reply":"2024-10-16T13:25:38.87128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('/kaggle/input/nlp-dataset/sample_submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:26:35.950085Z","iopub.execute_input":"2024-10-16T13:26:35.950979Z","iopub.status.idle":"2024-10-16T13:26:35.964068Z","shell.execute_reply.started":"2024-10-16T13:26:35.950935Z","shell.execute_reply":"2024-10-16T13:26:35.963232Z"},"trusted":true},"execution_count":null,"outputs":[]}]}